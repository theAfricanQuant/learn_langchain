{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba83f04a-3fae-4b82-8343-14e3da5d8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMCheckerChain\n",
    "from langchain.llms import OpenAI\n",
    "from config2 import set_environment\n",
    "set_environment()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "569b5498-972d-49db-9deb-ce4402caed6d",
   "metadata": {},
   "source": [
    "gpt-3.5-turbo-0125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e858c712-a641-44d4-8536-5eedf7a19585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMCheckerChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The echidna is the largest mammal that lays eggs.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0.7, model=\"gpt-3.5-turbo-instruct\")\n",
    "text = \"What type of mammal lays the biggest eggs?\"\n",
    "checker_chain = LLMCheckerChain.from_llm(llm, verbose=True)\n",
    "checker_chain.run(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2e03d-e01f-4d1b-8f93-f6fbefdddec7",
   "metadata": {},
   "source": [
    "1. **Instantiation**: \n",
    "   - The process here is called instantiation. In programming, instantiation is when you create a specific instance (or an object) of a class. A class can be thought of as a blueprint for creating objects. In this line, `OpenAI` is a class, and by calling it, we are creating an instance of this class.\n",
    "\n",
    "2. **Object and Variable Assignment**:\n",
    "   - `llm` is a variable. In programming, a variable is like a storage box where you can keep data. Here, we are storing the newly created instance of the `OpenAI` class in the variable named `llm`. After this line executes, `llm` will represent our specific instance of the `OpenAI` class.\n",
    "\n",
    "3. **Arguments and Parameters**:\n",
    "   - Inside the parentheses `()` are what we call arguments. Arguments are pieces of data that you pass to a method or a constructor (in this case, the constructor of the `OpenAI` class) when you call it. These arguments are used to set up the object with specific characteristics or data.\n",
    "   - In `temperature=0.7` and `model=\"gpt-3.5-turbo-instruct\"`, we are passing two arguments:\n",
    "     - `temperature=0.7`: Here, `temperature` is a parameter, and `0.7` is the value we are assigning to it. Parameters are like settings that can change how an object behaves. The `temperature` parameter likely controls some aspect of how the `OpenAI` class operates, in this context probably affecting the randomness or variability of responses generated by the model.\n",
    "     - `model=\"gpt-3.5-turbo-instruct\"`: Similarly, `model` is another parameter, and `\"gpt-3.5-turbo-instruct\"` is its value. This indicates the specific version or type of the OpenAI model that the instance will use.\n",
    "\n",
    "4. **Overall Explanation**:\n",
    "   - So, this line of code creates a new instance of the `OpenAI` class with specific settings (defined by the parameters `temperature` and `model`) and assigns this instance to the variable `llm`. After this line, you can use `llm` to access the functionalities provided by the `OpenAI` class, configured as per the specified `temperature` and `model`.\n",
    "\n",
    "\n",
    "Here language model is represented by the object \"llm,\" which is being utilized to generate a completion or response based on a specific query. \n",
    "\n",
    "The query, stored in the \"our_query\" variable is bieng passed to the model through llm object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a857ffb-97b7-4de3-9538-598512e55497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The currency of Nigeria is the Nigerian Naira (NGN).\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the currency of nigeria?\"\n",
    "completion = llm(query)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db7d751a-ecfa-4f19-9448-f81bb3c68b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricky/mambaforge/envs/langchain_ai/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GERMANY\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "llm = HuggingFaceHub(\n",
    "    model_kwargs={\"temperature\": 0.5, \"max_length\": 64},\n",
    "    repo_id=\"google/flan-t5-xxl\",\n",
    ")\n",
    "prompt = \"In which country is Oberursel, Germany?\"\n",
    "completion = llm(prompt)\n",
    "print(completion.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb7b81-3357-46ec-b0d3-0ea961bb4626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
