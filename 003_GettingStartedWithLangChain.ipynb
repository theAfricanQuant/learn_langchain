{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6b01c7f5-8d0b-432a-98ef-fc2a300e4243",
   "metadata": {},
   "source": [
    "#%%writefile .envv\n",
    "# Learning LangChain\n",
    "# in 20234\n",
    "# (c) Ricky Macharm, MScFE\n",
    "# https://www.SisengAI.com\n",
    "#\n",
    "#\n",
    "\n",
    "OPENAI_API_KEY=\"sk-thisIsSupposedTObeMYopenAItokenForMYeyesONLYandNotTobeShared\"\n",
    "HUGGINGFACEHUB_API_TOKEN=\"hf_AlsoGetYOURownHUggiNgFACEaccessToken\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d67ba167-50ec-4e56-b032-fb173c6d0191",
   "metadata": {},
   "source": [
    "# %%writefile cconfig.py\n",
    "# Learning LangChain\n",
    "# in 20234\n",
    "# (c) Ricky Macharm, MScFE\n",
    "# https://www.SisengAI.com\n",
    "#\n",
    "#\n",
    "\n",
    "\"\"\"This module extracts information from your `.env` file.\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "from pydantic import BaseSettings\n",
    "\n",
    "def return_full_path(filename: str = \".env\") -> str:\n",
    "    \"\"\"Returns the correct path of the `.env` file using the current working directory.\"\"\"\n",
    "    # Get the current working directory\n",
    "    cwd = Path.cwd()\n",
    "    # Join the current working directory with the filename\n",
    "    full_path = cwd / filename\n",
    "    return str(full_path)\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    \"\"\"Uses pydantic to define settings for project.\"\"\"\n",
    "\n",
    "    OPENAI_API_KEY: str\n",
    "    HUGGINGFACEHUB_API_TOKEN: str\n",
    "\n",
    "    class Config:\n",
    "        env_file = return_full_path(\".env\")\n",
    "\n",
    "# Create instance of `Settings` class that will be imported\n",
    "# in lesson notebooks and the other modules for application.\n",
    "settings = Settings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2ee888-9b54-470e-8c87-c0d1c9d86504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ebf4ae-ff3d-4309-8f66-cc8a63b5242f",
   "metadata": {},
   "source": [
    "### Fake LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "502d3d08-a305-498b-8147-23d5805ab36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.fake import FakeListLLM\n",
    "fake_llm = FakeListLLM(responses=[\"Hello\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10c0f965-c901-4147-9901-1b489a757ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FakeListLLM(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, responses=['Hello'], sleep=None, i=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58e632fb-ca65-413a-af08-b67f225b6e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: print(2 + 2)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 4\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "tools = load_tools([\"python_repl\"])\n",
    "responses = [\"Action: Python_REPL\\nAction Input: print(2 + 2)\", \"Final Answer: 4\"]\n",
    "llm = FakeListLLM(responses=responses)\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "agent.run(\"whats 2 + 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3976563-8d4a-4915-a3e1-0ccb9b950e1e",
   "metadata": {},
   "source": [
    "\n",
    "In this setup, an agent operates based on a React strategy and is tested with the question \"what's 2 + 2\". The agent utilizes a Python Read-Eval-Print Loop (REPL) tool for execution, which is triggered by the responses from the FakeListLLM. This mock language model, FakeListLLM, is programmed to provide two predetermined responses. The first response instructs the execution of a Python REPL action with the input \"print(2 + 2)\", and the second response directly provides the \"Final Answer: 4\". This demonstrates how the agent's decision-making process leads to executing Python code and obtaining a result based on the fake LLM's output. It's important to ensure the action name in the LLM's response aligns with the tool's name attribute, in this case, \"PythonREPLTool\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ae7ecdc-e256-4d1b-8418-12ebfa5a146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "class PythonREPLTool(BaseTool):\n",
    "    \"\"\"A tool for running python code in a REPL.\"\"\"\n",
    "    name = \"Python_REPL\"\n",
    "    description = (\n",
    "        \"A Python shell. Use this to execute python commands. \"\n",
    "        \"Input should be a valid python command. \"\n",
    "        \"If you want to see the output of a value, you should print it out \"\n",
    "        \"with `print(...)`.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50dd8fe2-086d-425d-9178-1b826da28f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 65536\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'65536'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0., model=\"gpt-3.5-turbo-instruct\",\n",
    "            openai_api_key=settings.OPENAI_API_KEY)\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "agent.run(\"whats 16 ** 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ee7b04-38a5-4366-9394-da9acb4c3d20",
   "metadata": {},
   "source": [
    "### Hugging Face: Powering NLP Innovation\n",
    "\n",
    "**Hugging Face** is a leading force in Natural Language Processing (NLP), renowned for its open-source and hosting solutions. As an American company, it excels in developing tools for machine learning applications.\n",
    "\n",
    "#### Transformers Python Library\n",
    "\n",
    "At its core, Hugging Face offers the **Transformers Python library**, a game-changer in NLP. It houses state-of-the-art models like **Mistral 7B**, **BERT**, and **GPT-2**, and smoothly integrates with **PyTorch**, **TensorFlow**, and **JAX**.\n",
    "\n",
    "#### Hugging Face Hub\n",
    "\n",
    "The **Hugging Face Hub** is their hub of innovation. Hosting over **120,000 models**, **20,000 datasets**, and **50,000 demo apps**, it's a thriving space for machine learning enthusiasts to collaborate and grow.\n",
    "\n",
    "#### Integration and Ease\n",
    "\n",
    "Hugging Face simplifies model integration. The **HuggingFaceHub** provides access to diverse models, while **HuggingFaceEmbeddings** works magic with sentence-transformer models.\n",
    "\n",
    "#### Rich Ecosystem\n",
    "\n",
    "Their ecosystem includes specialized libraries for:\n",
    "- **Datasets**: Efficient dataset processing.\n",
    "- **Evaluate**: Streamlined model evaluation.\n",
    "- **Simulate**: Ideal for simulations.\n",
    "- **Gradio**: Perfect for creating ML demos.\n",
    "\n",
    "#### Innovations\n",
    "\n",
    "Hugging Face made headlines with the **BigScience Research Workshop** and the release of **BLOOM**, an open LLM with **176 billion parameters**.\n",
    "\n",
    "#### Funding and Partnerships\n",
    "\n",
    "With **$2 billion in valuation**, they're well-funded. Partnerships with **Graphcore** and **AWS** aim to broaden their impact.\n",
    "\n",
    "#### Get Started\n",
    "\n",
    "To harness Hugging Face, create an account, and API keys at [Hugging Face Profile Settings](https://huggingface.co/settings/profile). Set your API token as **HUGGINGFACEHUB_API_TOKEN**.\n",
    "\n",
    "Explore it further with the **Flan-T5-XXL** model, a Google open-source gem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38feed4a-43ea-4488-8478-5c90e3322fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nigeria\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "llm = HuggingFaceHub(\n",
    "    model_kwargs={\"temperature\": 0.5, \"max_length\": 64},\n",
    "    repo_id=\"google/flan-t5-xxl\",\n",
    "    huggingfacehub_api_token=settings.HUGGINGFACEHUB_API_TOKEN\n",
    ")\n",
    "prompt = \"In which country is Jos, Plateau?\"\n",
    "completion = llm(prompt)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f440669d-d5a2-4af2-af2e-4c528538ef49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
