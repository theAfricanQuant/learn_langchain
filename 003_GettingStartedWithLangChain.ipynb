{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6b01c7f5-8d0b-432a-98ef-fc2a300e4243",
   "metadata": {},
   "source": [
    "#%%writefile .envv\n",
    "# Learning LangChain\n",
    "# in 20234\n",
    "# (c) Ricky Macharm, MScFE\n",
    "# https://www.SisengAI.com\n",
    "#\n",
    "#\n",
    "\n",
    "OPENAI_API_KEY=\"sk-thisIsSupposedTObeMYopenAItokenForMYeyesONLYandNotTobeShared\"\n",
    "HUGGINGFACEHUB_API_TOKEN=\"hf_AlsoGetYOURownHUggiNgFACEaccessToken\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d67ba167-50ec-4e56-b032-fb173c6d0191",
   "metadata": {},
   "source": [
    "# %%writefile cconfig.py\n",
    "# Learning LangChain\n",
    "# in 20234\n",
    "# (c) Ricky Macharm, MScFE\n",
    "# https://www.SisengAI.com\n",
    "#\n",
    "#\n",
    "\n",
    "\"\"\"This module extracts information from your `.env` file.\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "from pydantic import BaseSettings\n",
    "\n",
    "def return_full_path(filename: str = \".env\") -> str:\n",
    "    \"\"\"Returns the correct path of the `.env` file using the current working directory.\"\"\"\n",
    "    # Get the current working directory\n",
    "    cwd = Path.cwd()\n",
    "    # Join the current working directory with the filename\n",
    "    full_path = cwd / filename\n",
    "    return str(full_path)\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    \"\"\"Uses pydantic to define settings for project.\"\"\"\n",
    "\n",
    "    OPENAI_API_KEY: str\n",
    "    HUGGINGFACEHUB_API_TOKEN: str\n",
    "\n",
    "    class Config:\n",
    "        env_file = return_full_path(\".env\")\n",
    "\n",
    "# Create instance of `Settings` class that will be imported\n",
    "# in lesson notebooks and the other modules for application.\n",
    "settings = Settings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2ee888-9b54-470e-8c87-c0d1c9d86504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ebf4ae-ff3d-4309-8f66-cc8a63b5242f",
   "metadata": {},
   "source": [
    "### Fake LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502d3d08-a305-498b-8147-23d5805ab36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.fake import FakeListLLM\n",
    "fake_llm = FakeListLLM(responses=[\"Hello\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c0f965-c901-4147-9901-1b489a757ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FakeListLLM(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, responses=['Hello'], sleep=None, i=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e632fb-ca65-413a-af08-b67f225b6e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: print(2 + 2)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 4\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "tools = load_tools([\"python_repl\"])\n",
    "responses = [\"Action: Python_REPL\\nAction Input: print(2 + 2)\", \"Final Answer: 4\"]\n",
    "llm = FakeListLLM(responses=responses)\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "agent.run(\"whats 2 + 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3976563-8d4a-4915-a3e1-0ccb9b950e1e",
   "metadata": {},
   "source": [
    "\n",
    "In this setup, an agent operates based on a React strategy and is tested with the question \"what's 2 + 2\". The agent utilizes a Python Read-Eval-Print Loop (REPL) tool for execution, which is triggered by the responses from the FakeListLLM. This mock language model, FakeListLLM, is programmed to provide two predetermined responses. The first response instructs the execution of a Python REPL action with the input \"print(2 + 2)\", and the second response directly provides the \"Final Answer: 4\". This demonstrates how the agent's decision-making process leads to executing Python code and obtaining a result based on the fake LLM's output. It's important to ensure the action name in the LLM's response aligns with the tool's name attribute, in this case, \"PythonREPLTool\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae7ecdc-e256-4d1b-8418-12ebfa5a146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "class PythonREPLTool(BaseTool):\n",
    "    \"\"\"A tool for running python code in a REPL.\"\"\"\n",
    "    name = \"Python_REPL\"\n",
    "    description = (\n",
    "        \"A Python shell. Use this to execute python commands. \"\n",
    "        \"Input should be a valid python command. \"\n",
    "        \"If you want to see the output of a value, you should print it out \"\n",
    "        \"with `print(...)`.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50dd8fe2-086d-425d-9178-1b826da28f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to use the exponent operator\n",
      "Action: [Python_REPL]\n",
      "Action Input: 16 ** 4\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 65536\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'65536'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0., model=\"gpt-3.5-turbo-instruct\",\n",
    "            openai_api_key=settings.OPENAI_API_KEY)\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "agent.run(\"whats 16 ** 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ee7b04-38a5-4366-9394-da9acb4c3d20",
   "metadata": {},
   "source": [
    "### Hugging Face: Powering NLP Innovation\n",
    "\n",
    "**Hugging Face** is a leading force in Natural Language Processing (NLP), renowned for its open-source and hosting solutions. As an American company, it excels in developing tools for machine learning applications.\n",
    "\n",
    "#### Transformers Python Library\n",
    "\n",
    "At its core, Hugging Face offers the **Transformers Python library**, a game-changer in NLP. It houses state-of-the-art models like **Mistral 7B**, **BERT**, and **GPT-2**, and smoothly integrates with **PyTorch**, **TensorFlow**, and **JAX**.\n",
    "\n",
    "#### Hugging Face Hub\n",
    "\n",
    "The **Hugging Face Hub** is their hub of innovation. Hosting over **120,000 models**, **20,000 datasets**, and **50,000 demo apps**, it's a thriving space for machine learning enthusiasts to collaborate and grow.\n",
    "\n",
    "#### Integration and Ease\n",
    "\n",
    "Hugging Face simplifies model integration. The **HuggingFaceHub** provides access to diverse models, while **HuggingFaceEmbeddings** works magic with sentence-transformer models.\n",
    "\n",
    "#### Rich Ecosystem\n",
    "\n",
    "Their ecosystem includes specialized libraries for:\n",
    "- **Datasets**: Efficient dataset processing.\n",
    "- **Evaluate**: Streamlined model evaluation.\n",
    "- **Simulate**: Ideal for simulations.\n",
    "- **Gradio**: Perfect for creating ML demos.\n",
    "\n",
    "#### Innovations\n",
    "\n",
    "Hugging Face made headlines with the **BigScience Research Workshop** and the release of **BLOOM**, an open LLM with **176 billion parameters**.\n",
    "\n",
    "#### Funding and Partnerships\n",
    "\n",
    "With **$2 billion in valuation**, they're well-funded. Partnerships with **Graphcore** and **AWS** aim to broaden their impact.\n",
    "\n",
    "#### Get Started\n",
    "\n",
    "To harness Hugging Face, create an account, and API keys at [Hugging Face Profile Settings](https://huggingface.co/settings/profile). Set your API token as **HUGGINGFACEHUB_API_TOKEN**.\n",
    "\n",
    "Explore it further with the **Flan-T5-XXL** model, a Google open-source gem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38feed4a-43ea-4488-8478-5c90e3322fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricky/mambaforge/envs/langchain_ai/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIGERIA\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "llm = HuggingFaceHub(\n",
    "    model_kwargs={\"temperature\": 0.5, \"max_length\": 64},\n",
    "    repo_id=\"google/flan-t5-xxl\",\n",
    "    huggingfacehub_api_token=settings.HUGGINGFACEHUB_API_TOKEN\n",
    ")\n",
    "prompt = \"In which country is Jos, Plateau?\"\n",
    "completion = llm(prompt)\n",
    "print(completion.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f440669d-d5a2-4af2-af2e-4c528538ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GERMANY\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Where is Oberursel?\"\n",
    "completion = llm(prompt)\n",
    "print(completion.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8101816-e768-48a8-9fcf-e9eb555c7c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIGERIA\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Where is Lagos?\"\n",
    "completion = llm(prompt)\n",
    "print(completion.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "162c0bf3-1dc2-4f3a-814c-fb08dd60d771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nigeria\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Where is Lagos in Europe?\"\n",
    "completion = llm(prompt)\n",
    "print(completion.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "902b631e-6fe6-4699-9e5c-31875edea419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative AI (GAN) is a subset of machine learning that uses a network of intelligent agents to learn from data. It works by having a set of agents that are trained on data and then using these agents to predict future outcomes. The goal is to generate as many possible outcomes as possible in order to accurately analyze the data and make predictions. The steps of building a GAN model include understanding the data and training the agents; implementing the predictions; and monitoring the results of the predictions. To further develop the model, it is important to think of how the model can become more powerful and efficient.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "generate_text = pipeline(\n",
    "    model=\"aisquared/dlite-v1-355m\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    framework=\"pt\"\n",
    ")\n",
    "generate_text(\"In this chapter, we'll discuss first steps with generative AI in Python.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51541684-4b59-4b33-8e57-69de3a16cfac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
