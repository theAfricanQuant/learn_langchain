{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "657ea840-ca60-42f5-9bc1-a94bd5b0cd23",
   "metadata": {},
   "source": [
    "\n",
    "**Expanding the Capabilities of Language Models**\n",
    "\n",
    "In the realm of language models, we are witnessing a revolution marked by their ever-increasing fluency and sophistication. However, the journey doesn't end here. The true challenge lies in harnessing this fluency to develop language models that are not just eloquent, but also reliably capable assistants. This chapter delves into various strategies designed to imbue language models with enhanced intelligence, productivity, and trustworthiness.\n",
    "\n",
    "The overarching theme of our approach revolves around three core enhancements:\n",
    "\n",
    "1. **Utilizing Prompts Effectively**: We'll explore how carefully crafted prompts can significantly elevate the performance of language models. This isn't just about asking the right questions; it's about framing these questions in a way that guides the model towards more accurate and relevant responses.\n",
    "\n",
    "2. **Tool Integration**: By integrating external tools, we can compensate for the inherent limitations of language models, particularly in their world knowledge. This aspect covers how connecting to external data sources and services can enrich the model's responses, making them more grounded in reality and up-to-date.\n",
    "\n",
    "3. **Structured Reasoning Techniques**: We will delve into structured reasoning as a method to enhance the logical and analytical capabilities of language models. This involves teaching them to process information in a more organized and systematic manner, akin to how a skilled problem solver would approach a complex issue.\n",
    "\n",
    "Throughout this chapter, we will not only discuss these methods theoretically but also bring them to life through practical applications. Here's a sneak peek into what we'll cover:\n",
    "\n",
    "- **Combating Hallucinated Content**: A critical shortcoming of current language models is their tendency to produce hallucinated or inaccurate content. We will tackle this issue head-on by introducing automated fact-checking mechanisms. By cross-referencing the model's claims with available evidence, we aim to curb the spread of misinformation, ensuring that the information provided is not only fluent but also factually correct.\n",
    "\n",
    "- **Mastering Summarization**: A notable strength of language models lies in their ability to summarize content. We will investigate this capability further, examining how to enhance it through varying levels of prompt sophistication. Particularly for lengthy documents, we will introduce the concept of the map-reduce approach, a technique borrowed from computer science that helps in managing and summarizing extensive information efficiently.\n",
    "\n",
    "- **Extracting Information with Precision**: Moving forward, we will discuss how function calls can be used for extracting specific information from documents. This is a step towards more targeted and purposeful interactions with language models, where the focus is on retrieving precise data points rather than just general information.\n",
    "\n",
    "- **Application Development with Tool Integration**: To demonstrate the power of tool integration, we will develop an application that exemplifies how connecting to external data and services can greatly enhance the language model's utility, especially in compensating for its limited knowledge of the world.\n",
    "\n",
    "- **Applying Reasoning Strategies**: Finally, we will push the boundaries further by incorporating advanced reasoning strategies into our application. This will showcase how a language model, when equipped with the right tools and techniques, can not only process information but also reason through it in a more human-like manner.\n",
    "\n",
    "In summary, this chapter aims to transform the impressive fluency of language models into practical, reliable, and intelligent assistance. By bridging the gap between raw linguistic ability and applied intelligence, we're stepping into a future where language models become indispensable tools in our daily lives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc666296-4a79-4e9c-99eb-2ec4a1248a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMCheckerChain\n",
    "from langchain.llms import OpenAI\n",
    "from config_api import set_environment\n",
    "set_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da44f0e3-577b-4ee5-9b19-c785b50f8683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMCheckerChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The question is contradictory as mammals do not lay eggs. The largest eggs are laid by birds, such as the ostrich or emu, which are not mammals.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0.7, model=\"gpt-3.5-turbo-instruct\")\n",
    "text = \"What type of mammal lays the biggest eggs?\"\n",
    "checker_chain = LLMCheckerChain.from_llm(llm, verbose=True)\n",
    "checker_chain.run(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f293945a-4481-49d5-8063-22d767b8aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Monotremes, a type of mammal found in Australia and parts of New Guinea, lay the largest eggs in the mammalian world. The eggs of the American echidna (spiny anteater) can grow as large as 10 cm in length, and dunnarts (mouse-sized marsupials found in Australia) can have eggs that exceed 5 cm in length.\n",
    "• Monotremes can be found in Australia and New Guinea\n",
    "• The largest eggs in the mammalian world are laid by monotremes\n",
    "• The American echidna lays eggs that can grow to 10 cm in length\n",
    "• Dunnarts lay eggs that can exceed 5 cm in length\n",
    "• Monotremes can be found in Australia and New Guinea – True\n",
    "• The largest eggs in the mammalian world are laid by monotremes – True\n",
    "• The American echidna lays eggs that can grow to 10 cm in length – False, the American echidna lays eggs that are usually between 1 to 4 cm in length.\n",
    "• Dunnarts lay eggs that can exceed 5 cm in length – False, dunnarts lay eggs that are typically between 2 to 3 cm in length.\n",
    "The largest eggs in the mammalian world are laid by monotremes, which can be found in Australia and New Guinea. Monotreme eggs can grow to 10 cm in length.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41281d0b-bbf0-4308-ba48-ef853c1aa066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMCheckerChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' True'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker_chain = LLMCheckerChain.from_llm(llm, verbose=True)\n",
    "checker_chain.run(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6e7425-5419-47a0-96bd-b4149b7e24d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "prompt = \"\"\"\n",
    "Summarize this text in one sentence:\n",
    "{text}\n",
    "\"\"\"\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "summary = llm(prompt.format(text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a5aee2a-4407-4232-a5ba-0ea292bda5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The speaker wants to share a dull story from their childhood.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c1cd7f-aa59-4e9d-b878-2a15229e0fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_decorators import llm_prompt\n",
    "@llm_prompt\n",
    "def summarize(text:str, length=\"short\") -> str:\n",
    "    \"\"\"\n",
    "    Summarize this text in {length} length:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "    return\n",
    "summary = summarize(text=\"let me tell you a boring story from when I was young...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73c6e2b4-41fc-40b2-9345-e74fb6c05ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, OpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Summarize this text: {text}?\"\n",
    ")\n",
    "runnable = prompt | llm | StrOutputParser()\n",
    "summary = runnable.invoke({\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ed19122-74e3-4cc6-bd0e-50be486f54bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nMonotremes, found in Australia and parts of New Guinea, lay the largest eggs in the mammalian world. However, the eggs of the American echidna and dunnarts, both types of monotremes, are not as large as previously thought. While the American echidna's eggs can reach up to 10 cm in length, they are typically between 1 to 4 cm long. Dunnarts, on the other hand, lay eggs that are usually between 2 to 3 cm in length, not exceeding 5 cm. \""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b0918da-bdac-498f-a55d-7275bcc3a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Article: { text }\n",
    "You will generate increasingly concise, entity-dense summaries of the above article.\n",
    "Repeat the following 2 steps 5 times.\n",
    "Step 1. Identify 1-3 informative entities (\";\" delimited) from the article which are missing from the previously generated summary.\n",
    "Step 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the missing entities.\n",
    "A missing entity is:\n",
    "- relevant to the main story,\n",
    "- specific yet concise (5 words or fewer),\n",
    "- novel (not in the previous summary),\n",
    "- faithful (present in the article),\n",
    "- anywhere (can be located anywhere in the article).\n",
    "Guidelines:\n",
    "- The first summary should be long (4-5 sentences, ~80 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~80 words.\n",
    "- Make every word count: rewrite the previous summary to improve flow and make space for additional entities.\n",
    "- Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n",
    "- The summaries should become highly dense and concise yet self-contained, i.e., easily understood without the article.\n",
    "- Missing entities can appear anywhere in the new summary.\n",
    "- Never drop entities from the previous summary. If space cannot be made, add fewer new entities.\n",
    "Remember, use the exact same number of words for each summary.\n",
    "Answer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e24ea2e7-3a35-4085-9f42-f51c19e464e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, OpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Summarize this text: {text}?\"\n",
    ")\n",
    "runnable = prompt | llm | StrOutputParser()\n",
    "summary = runnable.invoke({\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cef9230f-7963-47f3-b7ba-d820f14419d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMonotremes, found in Australia and New Guinea, lay the largest mammalian eggs, with the American echidna and dunnarts having eggs that typically range from 1 to 4 cm and 2 to 3 cm in length, respectively.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca9c29c0-3a99-4e8c-a827-585d92852811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nThe article discusses the benefits and challenges of using Matplotlib for data visualization in Python, particularly for business analysis. It includes tips for effectively using Matplotlib, such as learning its terminology and using the object-oriented interface. The article also provides links to helpful resources and code examples. There is also a discussion on the effectiveness of Matplotlib in the business world and comparisons to other data visualization tools.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "pdf_file_path = \"matplotlib.pdf\"\n",
    "pdf_loader = PyPDFLoader(pdf_file_path)\n",
    "docs = pdf_loader.load_and_split()\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e870831-3e50-4418-8b60-325c3e63f7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why did the light bulb go to therapy?\n",
      "Because it was feeling a bit burned out.\n",
      "Total Tokens: 27\n",
      "Prompt Tokens: 8\n",
      "Completion Tokens: 19\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "llm_chain = PromptTemplate.from_template(\"Tell me a joke about {topic}!\") | OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "with get_openai_callback() as cb:\n",
    "    response = llm_chain.invoke(dict(topic=\"light bulbs\"))\n",
    "    print(response)\n",
    "    print(f\"Total Tokens: {cb.total_tokens}\")\n",
    "    print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "    print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "    print(f\"Total Cost (USD): ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39873d9d-75c8-48a1-a0b0-6640b5cf4e1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RunnableSequence' object has no attribute 'generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m input_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocks\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      3\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomputer\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      4\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshoes\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      5\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0m \u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m(input_list)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RunnableSequence' object has no attribute 'generate'"
     ]
    }
   ],
   "source": [
    "input_list = [\n",
    "    {\"product\": \"socks\"},\n",
    "    {\"product\": \"computer\"},\n",
    "    {\"product\": \"shoes\"}\n",
    "]\n",
    "llm_chain.generate(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdba64-cb5d-41e1-9fd5-aab81ee354b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
